{"runs": [{"env_config": {"env_map": [[0, 0, 0, 0, 0], [0, 1, 0, 1, 0], [0, 0, 0, 1, 0], [0, 1, 0, 0, 1], [0, 0, 1, 0, 0]], "env_name": "vector_grid_goal", "grid_dims": [5, 5], "player_location": [0, 0], "goal_location": [4, 4]}, "seed": 6000, "n_episodes": 20, "max_steps": 30, "visualizer": false, "vis_steps": false, "vis_frequency": 100, "output_path": "multi_policy_output", "output_dict": {}, "debug_mode": false, "hyperpolicy": "a_stochastic", "gamma": 0.9, "lr": 0.3, "max_epsilon": 0.5, "epsilon_decay": 0.001, "min_epsilon": 0.001, "mip_flag": true, "cycle_flag": true, "analytic_policy_update_frequency": 500, "random_endpoints": false, "reward_endpoints": true, "analytic_policy_active": false, "analytic_policy_chance": 0.3, "hp_struct": {"policy_objects": [{"policy_name": "q_policy", "prob_trajectory": [0.5, 0.5005, 0.5009995, 0.5014985005, 0.5019970019994999, 0.5024950049975005, 0.502992509992503, 0.5034895174825105, 0.503986027965028, 0.504482041937063, 0.5049775598951258, 0.5054725823352308, 0.5059671097528955, 0.5064611426431427, 0.5069546815004995, 0.507447726818999, 0.5079402790921801, 0.5084323388130878, 0.5089239064742748, 0.5094149825678005]}, {"policy_name": "random_policy", "prob_trajectory": [0.5, 0.4995, 0.4990005, 0.4985014995, 0.4980029980005, 0.4975049950024995, 0.497007490007497, 0.4965104825174895, 0.496013972034972, 0.495517958062937, 0.4950224401048741, 0.4945274176647692, 0.49403289024710445, 0.4935388573568574, 0.4930453184995005, 0.492552273181001, 0.49205972090781996, 0.4915676611869122, 0.49107609352572523, 0.4905850174321995]}]}, "np_seed": 6991, "env_seed": 6991, "python_seed": 6991, "color": "green", "label": " policy_chance: 0.3 seed: 6991"}, {"env_config": {"env_map": [[0, 0, 0, 0, 0], [0, 1, 0, 1, 0], [0, 0, 0, 1, 0], [0, 1, 0, 0, 1], [0, 0, 1, 0, 0]], "env_name": "vector_grid_goal", "grid_dims": [5, 5], "player_location": [0, 0], "goal_location": [4, 4]}, "seed": 6000, "n_episodes": 20, "max_steps": 30, "visualizer": false, "vis_steps": false, "vis_frequency": 100, "output_path": "multi_policy_output", "output_dict": {}, "debug_mode": false, "hyperpolicy": "a_stochastic", "gamma": 0.9, "lr": 0.3, "max_epsilon": 0.5, "epsilon_decay": 0.001, "min_epsilon": 0.001, "mip_flag": true, "cycle_flag": true, "analytic_policy_update_frequency": 500, "random_endpoints": false, "reward_endpoints": true, "analytic_policy_active": false, "analytic_policy_chance": 0.3, "hp_struct": {"policy_objects": [{"policy_name": "q_policy", "prob_trajectory": [0.5, 0.5005, 0.5009995, 0.5014985005, 0.5019970019994999, 0.5024950049975005, 0.502992509992503, 0.5034895174825105, 0.503986027965028, 0.504482041937063, 0.5049775598951258, 0.5054725823352308, 0.5059671097528955, 0.5064611426431427, 0.5069546815004995, 0.507447726818999, 0.5079402790921801, 0.5084323388130878, 0.5089239064742748, 0.5094149825678005]}, {"policy_name": "random_policy", "prob_trajectory": [0.5, 0.4995, 0.4990005, 0.4985014995, 0.4980029980005, 0.4975049950024995, 0.497007490007497, 0.4965104825174895, 0.496013972034972, 0.495517958062937, 0.4950224401048741, 0.4945274176647692, 0.49403289024710445, 0.4935388573568574, 0.4930453184995005, 0.492552273181001, 0.49205972090781996, 0.4915676611869122, 0.49107609352572523, 0.4905850174321995]}]}, "np_seed": 2273, "env_seed": 2273, "python_seed": 2273, "color": "green", "label": " policy_chance: 0.3 seed: 2273"}], "generation_time": 1679950920.1147773, "variables": ["hp_struct", "analytic_policy_chance", "np_seed"]}